\chapter{Implementierung aufbauend auf bestehenden Technologien, REST API und Continuous Delivery}

\section{Sinatra und PostgreSQL zur Optimiertung des bestehenden Technologiestacks}
Wie bereits in vorangegangenen Kapiteln beschrieben, bieten Microservices die Möglichkeit zum optimierten Einsatz von Technologien. Für die zu entwickelnde Anwendung gab es diverse Optimierungsmöglichkeiten. Hier sollte zum Einen insbesondere auf die Wahl der Datenbanktechnologie, zum Anderen vor Allem auf die Wahl des Frameworks geachtet werden.

\subsection{Wahl des Webframeworks}
Die Hauptanwendung ist im Ruby Framework Ruby on Rails\cite{rails} entwickelt worden. Ruby on Rails ist jedoch als Framework zu heavy-weight und mit zu viel Overhead verbunden, als das es sich für einen schnellen, minimalistischen Microservice eignen würde. Ruby on Rails ist an erster Stelle für monolithische Anwendungen entwickelt.~\cite[][]{rails:doctrine}
Hierbei ist nicht nur die Performance entscheident, sondern auch die Struktur des Codes. Rails als traditionelles Model-View-Controller Framework\cite[][]{wiki:mvc} eignet sich somit vor Allem auch nicht aufgrund seiner Struktur. Die minimalistischere Rails API Variante\cite{rails:api} hat zwar einen geringeren overhead als Rails, für einen geschwindigkeitsorientierten Microservice bieten sich weitere Optimierungen jedoch an.

\begin{figure}[!ht]
    \centering
    \caption{Geschwindigkeitsvergleich Rails, Rails API und Sinatra \cite{newrelic:soa}}
    \label{fig:speed}
    \includegraphics[width=\textwidth]{rails_sinatra}
\end{figure}

Alternativen bilden sogenannte Microframeworks\cite{wiki:micro}. Microframeworks zeichnen sich im Gegensatz zu full-stack Frameworks dadurch aus, das viele der Funktionen nicht Teil des mitgelieferten Umfangs sind. In den meisten Sprachen gibt es diverse Microframeworks, wie z.B. Flask\cite{flask} für Python, Express\cite{expressjs} für Node, Sparkjava\cite{sparkjava}, oder das Sinatra Framework\cite{sinatra} für Ruby. Die Sprache Go\cite{golang} kommt bereits mit gut ausgebauten net/htttp Paketen und umfasst dadurch die meisten üblichen Funktionen schon ohne Framework.

Zwar gibt es Geschwindigkeitsunterschiede in diesen Frameworks\cite[vgl.][]{frameworks}, im Vergleich zu klassischen full-stack Frameworks sind diese aber unerheblich. Da die Datenbank in der bestehenden Anwendung den größten Flaschenhals bildet (FIX STATS), muss hier nicht zwangsläufig das beste Framework gewählt werden. Stattdessen sollte auf die bestehende Firmenstruktur geachtet werden. Da fast die gesamte Backendtechnologie bisher mit der Programmiersprache Ruby entwickelt ist und es somit keine anderen im Produktionsbetrieb eingesetzt wird, stellt es eine Schwierigkeit dar, eine neue Programmiersprache in die Firma zu integrieren. Vor allem da der neue Microservice auch mit einem komplett eigenen Produktionssetup verbunden ist, stellt eine in der Firma bisher unbekannte Programmiersprache eine ganz eigene Herausforderung dar. Um die Wartbarkeit des Systems hoch zu halten und die Risiken für den Betrieb zu minimieren, entschied ich mich daher auch im neuen Microservice die Programmiersprache Ruby einzusetzen. Da das Framework Ruby on Rails überproprtioniert ist und nicht den Anforderungen entspricht, entschied ich mich für den Einsatz des Ruby Frameworks Sinatra. 
Sinatra ist nach Ruby on Rails das mit Abstand beliebteste Ruby Framework\cite[vgl.][]{ruby2015} und wird daher von den meisten Ruby Web Tools unterstützt.

Wie bereits erwähnt, ist Sinatra ein sogenanntes Microframework. Sinatra selbst bringt also nicht viel Logik, die die Entwicklung beeinflusst. Einige Dinge die Sintra erleichtert, sind vor Allem das Routing. Hier kann schnell eine Routing Struktur erschaffen werden, die Definition von Routen und deren Antworten ist sehr komfortabel und schnell eingerichtet. Sinatra ist vor Allem auch nicht darauf ausgelegt in Antworten HTML zu rendern, so kann leicht eine JSON Response definiert werden.
Eine Route zum Anlegen von Resourcen kann demnach so definiert werden:
\begin{lstlisting}[language=Ruby]
class SomeController < Sinatra::Base
  post '/resources' do
    data = JSON.load(request.body.read)
    [...] # some actions to save the resource
    # return appropriate 201 code and json with access key
    [201, { data: { key: some_key  } }.to_json }]
  end
end
\end{lstlisting}

Weiterhin erleichtert Sinatra das Betreiben eines Webservers und bietet eine Schnittstelle zum Ruby Standard Webserver Interface Rack\cite{rack}. Hier wird dem Entwickler viel Arbeit abgenommen. Viele Tools zum Betreiben von Webservices, z.B. im Bereich des Monitorings oder des Loggings unterstützen ebenfalls das Sinatra Framework. So bringt Sinatra also nicht viel overhead out of the box, bringt aber die Möglichkeit zur Nutzung vieler praktischer Erweiterungen.

Als Webserver wählte ich den Ruby Webserver Puma\cite{puma}. Puma ist ein Webserver mit verhältnismäßig geringem Speicherverbrauch, dadurch bietet er sich vor Allem für den Betrieb eines Microservices an.

(FIX Webserver? Puma... hier oder später?)

\subsection{Datenbanktechnologie}
Da die Datenbank das scheinbar größte Problem der Performance in der bestehenden Anwendung bildet, ist es hier dringend notwendig die eingesetzte Technologie zu überdenken. Zwar ist MongoDB von der Idee her keine schlechte Wahl für die Userprofile, die Art wie Profildaten abgefragt werden, passt aber nicht gut zum dokumentorientierten Ansatz von MongoDB.
Die Schemalosigkeit von MongoDB in Zusammenarbeit mit den recht variablen Profilen war ursprünglich der Hauptgrund diese Technologie einzusetzen. Nutzerprofile sind stark unterschiedlich, viele mit ja beantworteten Fragen führen zu weiteren Fragen (z.B. ``Haben Sie Kinder?'', ``Wie viele Kinder haben Sie?'', ``Wie alt ist Kind x?''). Hierbei bietet es sich durchaus an MongoDB mit seiner Embedded Document Struktur zu benutzten, statt unzählige 1 zu n Beziehungen zu verwalten.
Bei der Abfrage der Daten versprucht MongoDB Geschwindigkeitsvorteile, wenn man einzelne Dokumente aus der Datenbank erhalten möchte. So kann zum Beispiel die Struktur einer Powerpoint Präsentation wie folgt abgebildet werden:
\begin{lstlisting}[language=Ruby]
{
    presentationId: 1,
    title: "A Presentation",
    author: "me",
    slides: [
        {
            slideId: 1,
            slideOrder: 1,
            elements: [
                {
                    elementId: 1,
                    elementXPos: 100,
                    ...
                },
                ...
                }
            ]
        },
        ...
    ]
}
\end{lstlisting}
Eine Präsentation kann nun mit nur einer Abfrage, ohne jegliche Joins aus der Datenbank geladen werden. Die ganze Präsentation kann vorgerendered werden und die Anwendung zur Erstellung oder Präsentation von Präsentationen ohne weiteres Nachladen genutzt werden. Hier liegt MongoDB's Stärke: Strukturen können in ihrer natürlichen Form abgebildet werden und dokumentorientiert schnell aus der Datenbank geladen werden.
So ist auch der Aufbau der Profile konzipiert worden. Für die Verwaltung der Daten und für die Pflege der Profile durch die Nutzer ist dieser Aufbau durchaus angebracht.
Beim Erstellen einer Query und dessen Ausführung über die Gesamtpopulation ist diese Aufbau aber nicht optimal. Hier sind nie alle Profilfelder eines Nutzers relevant, sondern lediglich ein Querschnitt über alle Nutzer. Queries sehen in der Regel wie folgt aus:
\begin{lstlisting}[language=Ruby]
{
    "profile.participations.response_rate.value": {
        "$lt": 0.3
    },
    "profile.basic.locale.value": {
        "$in": ["de", "de-AT"]
    },
    "profile.basic.age.value": {
        "$gt": 21,
        "$lte": 100
    }
}
\end{lstlisting}

Hier wird auf eine verhältnismäßig geringe Zahl von Profilfelder, meist weniger als 10, über die gesamte Population gequeried. Weiterhin werden dann nicht gesamte Nutzerobjekte zurückgegeben, sondern lediglich die Anzahl der passenden Nutzer, deren Ids oder Antwortraten. Die MongoDB query Struktur ist dafür schlichtweg nicht optimiert. Hinzu kommt die extreme Verschachtelung der Datenstruktur. So werden nicht nur Profildaten wie Kinder in ein Subdokument gruppiert, es gibt auch noch thematische Unterteilungen der Profildaten, ``basic'' für die allgemeinen personenbezogenen Daten, ``basic.education'' für Daten über den Bildungsgrad.
Hinzu kommt die relative Größe der Datenbank. Knapp 400.000 Userdaten mit bis zu 176 ausgefüllten Prodfilfeldern passen aktuell nicht einmal mehr in den Arbeitsspeicher der Server. Nicht alle Felder können logischerweise mit Indexen abgedeckt werden, die relative Verteilung der Queries umfasst aber alle Felder. Zwar gibt es besondere Häufungen der Queries bei bestimmten Feldern und diese sind auch durch Indexes abgedeckt, vor Allem aber die Queries auf die anderen Felder verlangsamen die Anwendung nicht unerheblich.

Hier besteht schlicht eine Diskrepanz zwischen den Queryanforderungen. Zum Einen wird hier dokumentenorientiert, zum Anderen spaltenorientiert gearbeitet. % (FIX TOO ABSOLUTE, it's not column oriented after all)
Ein Ansatz diese Diskrepanz zwischen Nutzersampling und Profilpflege zu lösen, bietet die Command Query Responsibility Segregation (CQRS).~\cite[][]{fowler:cqrs} Gemäß der Anforderungen verschiedener Services bietet es sich hier an, die Darstellung von Daten, die theoretisch identisch sind, auf verschiedene Anwendungfälle zu optimieren. Auf Code Ebene können zum Beispiel separate Models genutzt werden um die Daten in individuelle Repräsentationsformen zu bringen. Auf Ebene der Datenbank kann ein komplett anderes Schema zur Repräsentation der Daten genutzt werden.

\begin{figure}[!ht]
    \centering
    \caption{Aufspaltung zur Lösung der Anforderungsdiskrepanz}
    \label{fig:orientationsplit}
    \includegraphics[width=\textwidth]{orientation_comparison}
\end{figure}

Aufgrund der offensichtlichen Mängel im Schema im Bezug auf die Nutzerqueries bot es sich an, die Datenbanktechnologie zu wechseln und stattdessen eine SQL Datenbank zu verwenden. Im Gegensatz zum Wechsel der Programmiersprache, stellt der Einsatz einer anderen Datenbanktechnologie im konkreten Fall keine große Hürde dar. Im Betrieb besteht bereits eine MySQL\cite{mysql} Datenbank als Data Warehouse und eine PostgreSQL\cite{postgres} Datenbank für eine für einen Kunden betriebene Anwendung. Daher besteht Erfahrung sowohl in der Entwicklung mit, als auch dem Betrieb von SQL Datenbanken.

Die Hauptaufgabe besteht nun darin, die bestehende, verschachtelte Struktur der MongoDB Datenbank in ein SQL Format zu übersetzen.
In \autoref{fig:fields} sind die bisher eingesetzten Ruby Klassen zur Abbildung der MongoDB Datenstruktur abgebildet. 

\begin{figure}[!ht]
    \centering
    \caption{Vereinfachtes Klassendiagramm zur Darstellung der vorhandenen Profilfelder}
    \label{fig:fields}
    \includegraphics[width=\textwidth]{field_types}
\end{figure}

Eine Herausforderung bilden hier vor Allem die Felder der Klasse ChoiceFieldType. Die anderen Felder können problemlos in eine Flache Struktur überführt werden. Für Choice Felder, sollte nun gemäß der zweiten Normalform (FIX WELCHE NORMALFORM? QUELLE) eine eigene Tabelle mit Relation angelegt werden. Die MultipleChoice Felder müssten weiterhin mit einer `has-many' Relation abgebildet werden, was zu vielen Joins bei Queries führen würde. Da Joins im Allgemeinen verhältnismäßig langsam sind (FIX QUELLE), ist dies in Anbetracht der Aufgabenstellung ein Problem. Da die Datenbank im Microservice jedoch lediglich zu möglichst schnellen Abfrage der Daten, nicht aber zur Pflege und Organisation der Daten genutzt wird, ist es hier vertretbar eine denormalisierte Struktur zu wählen. So entschloss ich mich für den Einsatz von Bitstrings. Jede Auswahlmöglichkeit wird hier durch ein Bit repräsentiert. So kann zum Beipsiel die Mehrfachauswahl von Städten in Berlin, mit den drei Auswahlmöglichkeiten Hamburg, Berlin und München, auf einen drei Bit langen Bitstring abgebildet werden. Der Bitstring `010' in der Datebank bedeutet dann, dass nur die Option Berlin, nicht aber die Optionen Hamburg und München ausgewählt wurden. Dies spart zum Einen Platz in der Datenbank, zum Anderen reduziert es den Einsatz von Datenbankjoins. Es muss natürlich ein Overhead beim Übersetzen der alten Queries in ein Bitstring Format eingeplant werden. Weiterhin wird hier eine Kopplung zwischen Code und Datenbank eingeführt. Wenn sich die Optionen in der Datenbank ändern, muss immer zusätzlich zu allen anderen Stellen diese eine Stelle im Code aktualisiert werden.

Eine weitere Schwierigkeit stellen hier die EmbedsMany Felder dar. Auch hier ist eine `has-many` Relation notwendig, diese kann aber nicht, wie bei sich wiederholenden Auswahlfeldern, durch einen Bitstring ersetzt werden. (FIX MORE STUFF)

Zusätzlich zur relationalen Datenbank setzte ich in der Entwicklung weiterhin Redis\cite{redis} als Zwischenspeicher ein. Redis ist ein in-memory data store, der sowohl zu Datenbankzwecken, als auch zu caching Zwecken genutzt werden kann. Da die Daten ausschließlich im Arbeitsspeicher des Systems abgelegt werden, können hier sehr hohe Geschwindigkeiten erreicht werden.
Zunächst überträgt die Hauptanwendung in Form eines POST requests die Query. Diese wird dann in Redis gespeichert. Die errechneten Queryergebnisse werden dann ebenfalls in Redis gespeichert. Die Ergebnisse können dann jederzeit von der Hauptanwendung abgefragt werden. Außerdem ist es möglich und perspektivisch geplant, die Geschwindigkeit von Redis für das Caching zu nutzen. Es kann überprüft werden ob übertragene Queries bereits bekannt sind und anhand dessen Alters die Ergebnisse übernommen werden. Weiterhin kann hier Performance gewonnen werden, da keine langfristige Persistenz gefordert ist. So kann Redis einzig und allein im Arbeitsspeicher speichern und muss nicht, wie sonst üblich, jede Änderung auf der Festplatte speichern.\cite{redis:faq}

\subsection{Architektur des Microservices}
Wie bereits beschrieben, handelt es sich beim entwickelten Microservice streng genommen lediglich um eine Query Schnittstelle zu einer Datenbank. Der Overhead soll hier möglichst gering gehalten werden. Da in der bestehenden Anwendung möglichst wenig Änderungen vorgenommen werden sollen und die Schnittstelle zur alten Datenbank übergangsweise weiterhin bestehen soll, bietet es sich an, an den Microservice zum Abfragen der Daten die bestehenden Datenbankfelnamen zu übergeben. Die bestehende Schnittstelle zu MongoDB bietet hier eine praktische $.to_json$ Methode mit der ein Query leicht in ein gut übertragbares Format überführt werden kann. Eine erstellte Abfrage auf alle Nutzer die als Sprache deutsch angegeben haben

\begin{lstlisting}[language=Ruby]
User.where(:'profile.basic.locale.value' => 'de')
\end{lstlisting}

\noindent kann so leicht in ein JSON-Format überführt werden:

\begin{lstlisting}[language=Ruby]
User.where(:'profile.basic.locale.value' => 'de').selector.to_json
=> { "profile.basic.locale.value": "de" }
\end{lstlisting}

\noindent So bildet das Übersetzen der übergebenen einen wesentlichen Teil des entwickelten Microservices. (FIX KOPPLUNG erklären und rechtfertigen)

Einen weiteren wesentlichen Bestandteil bildet das handhaben des übergebenen JSON Strings. Dieser wird im ersten Schritt anhand einer JSON Schema\cite{jsonschema} Definition validiert. So wird sichergestellt das er wohlformattiert ist und den gestellten Anforderungen entspricht. Hier kann vor dem Schritt des wirklichen parsens ggf. noch einmal Last reduziert werden. War die Validierung erfolgreich wird der übergebene JSON String geparsed. Hierzu habe ich einen Parser entwickelt, der das übergeben MongoDB JSON Format in eine PostgreSQL kompatible Notation überführt. Schnell wird jedoch deutlich, dass es weitaus komplexere Querykonstrukte gibt. Da wäre zum Einen der Einsatz von Vergleichsoperatoren. Hier können leicht auch solche Queries entstehen:

\begin{lstlisting}[language=Ruby]
User.where(
    :'profile.basic.locale.value'.nin => ['de', 'de-AT', 'de-CH'],
    :'profile.automotive.car_amount.value'.gt => 3,
    :'profile.automotive.car_amount.value'.lte => 10
).selector.to_json
=> 
{
    "profile.basic.locale.value": {
        "$nin": ["de","de-AT","de-CH"]
    },
    "profile.automotive.car_amount.value": {
        "$gt": 3,
        "$lte": 10
    }
}
\end{lstlisting}

\noindent Dies muss der Parser also auch übersetzen können. Im gleichen Schritt werden, neben dem Parsen, auch die Datenbankfeldnamen übersetzt.

(FIX DEPLOYMENT/Continuous deployment??)
(FIX Funktion?? Was passiert genau im Service? Hier? Wo??)
(FIX Unterpunkte?)
(FIX Testing - how to test Microservices?)

\section{Schaffung einer standardisierten REST Schnittstelle}
Einen entscheidenden Unterschied zwischen Microservice Architektur und monolithischer Entwicklung, bildet die Schnittstelle zwischen den Anwendungsteilen. Während im Monolithen simple code calls stattfinden, muss für die Kommunikation zwischen verschiedenen Servies zunächst ein geeignetes Protokoll zum Austausch gefunden werden.
Da hier eben kein durch die Programmiersprache vorgeschriebener Standard besteht, ist es hier wichtig ein geeignetes Austauschformat zu definieren.
Um Änderungen sowohl im Client, also auch im Service möglich zu machen, sollten keine sprachgebundenen Technologien eingesetzt werden. Somit kann sichergestellt werden, das möglichst geringe Änderungen anfallen, sollte ein neuer Client oder Änderungen am bestehenden System zum Einsatz einer neuen Programmiersprache führen.

Eine populäre Schnittstellentechnologie ist der Einsatz von Remote Procedure Calls (RPC). RPC verfolgt das Hauptziel, remote calls wie lokale Aufrufe wirken zu lassen. Dier ermöglicht es schnell Server-Client Anwendungen zu entwickeln. Zwar sind RPC Lösungen häufig technologiegebunden, es gibt jedoch auch diverse Lösungen die verschiedene Technologien unterstützen. Ein großer Nachteil von RPC wird jedoch bei komplexeren Anwendungen auffällig: Remote Calls sind keine Localaufrufe.~\cite[][Seite 47]{newman2015building} Zwar erlaubt RPC es durch ``verstecken'' der Implementierungsdetails, schnell einfache Client-Server Anwendungen zu entwickeln, mit der Zeit wird aber deutlich, dass mitunter feinere Entwicklungsmöglichkeiten notwendig sind. Hier fehlt es dann oft an besserer technologischer Kontrolle.

Eine Alternative zu RPC, die vor Allem in den letzten Jahren an Popularität gewonnen hat, ist der Representational State Transfer (REST). Im Gegensatz zu RPC, das ursprünglich für Verteilte Systeme innerhalb eines Netzwerkes oder Netzwerkverbundes entwickelt wurde, ist REST eng an das Internet gekoppelt. Nicht zuletzt deswegen wird REST, trotz relativer Protokollunabhängigkeit, meist mit dem Hypertext Transfer Protocol (HTTP) verwendet. Die prominenten HTTP Verben POST, GET, PUT und DELETE lassen sich direkt zu den CRUD Operationen Create, Read, Update und Delete übersetzten. Eine REST Grundlage stellt die methodische Unabhängigkeit von Resourcen dar. Methoden sollten sich auf allen Resourcen gleich verhalten. So kann mit Hilfe der HTTP Verben durch verschiedene Request auf eine Resource, unterschiedliche Handlungen abgebidet werden. Statt die Methoden $createResourceX$, $readResourceX$, $updateResourceX$ und $deleteResourceX$ zu unterscheiden, kann eine einfache und abstrakte Form der Form $VERB\ RESOURCE$ genutzt werden um alle Methoden abzubilden. So können Methoden auf Queries also durch simple HTTP Request wie $POST\ /queries$ und $GET\ /queries$ abgebildet werden. Ein weiterer Vorteil der relativen Nähe zu HTTP, ist gute Unterstützung dieser Technolgie. Viele Technoligien die mit HTTP zum Einsatz kommen, wie z.B. Caching und Load Balancing, können leicht auch mit REST eingesetzt werden.

(FIX QUELLEN!!)

Weiterhin ist REST in der Wahl des eingesetzten Austauschformats frei. Populäre Möglichkeiten sind hier z.B. JSON oder XML. Da die bisherige Datenbankschnittstelle einen direkten Export zu JSON bietet, bietet es sich an diese hier einzusetzen. Generell ist der Support von JSON in Ruby sehr gut. Außerdem bietet auch die Datenbankschnittstelle für PostgreSQL JSON Unterstützung. (FIX FORMULIERUNG)

Da das eingesetzte JSON Format frei wählbar ist und REST ebenfalls wenig Ansprüche an die Form der Daten hat, bietet es sich hier an unterstützend eine Technologie zur Definition des JSON Formats einzusetzen. Hier gibt es zum Beipsiel JSON Schema. JSON Schema erlaubt es die erwartete Struktur der übertragenen Daten, z.B. bei POST Requests, abstrakt festzulegen. Dies erlaubt zum Einen leichte Nachvollziehbarkeit der Schnittstelle, zum Anderen eine automatische Validierung der übergebenen Daten. So muss nicht mit dem parsen der Daten begonnen werden, ohne das vorher sichergestellt ist, das diese semantisch korrekt sind.

Weiterhin ist es wichtig die erstellte API gut zu dokumentieren. Hier gibt es ebenfalls gute Tools die eingesetzt werden können. Ich nutze hierzu die RESTful API Modelling Language (RAML) \cite{raml}. RAML erlaubt es eine Schnittstelle in einem Maschinen-lesbaren Format zu dokumentieren. Dies erlaubt es automatische API Tests generieren zu lassen. So kann sichergestellt werden, dass die API Dokumentation immer auf dem aktuellsten Stand ist. Denn wenn die API, nicht aber die Dokumentation aktualisiert wird, würden hier die generierten Tests fehlschlagen. Dies ist für Verteilte Systeme besonders wichtig. RAML arbeitet hierzu mit JSON Schema zusammen um Beispielrequests zu definieren. Weiterhin lässt sich mit Tools wie RAML to HTML\cite{raml2html} leicht eine interaktive, menschenlesbare Dokumentation der API erstellen. Hier finden sich dann automatisch auch die Beispielrequests und -responses der API in JSON Format. Die Dokumentation der entwickelten API ist so für Entwickler in Form einer Webseite\cite{prophetdoku} nachvollziehbar. 

REST vor Allem im gemeinsamen Einsatz mit JSON-Schema und RAML, bildet eine reife Technologie, die sich für den Einsatz in der API Programmierung hervorragend eignet.

(FIX RAM console)

\section{Integration des Microservices in den Monolithen}
Wie bereits im vorangegangenen Kapitel beschrieben, beschloss ich den neuen Microservice mit Hilfe eines dem Strangler Pattern ähnlichen Prinzips in die bestehende Anwendung einzubinden.
Der Einsatz des Flipper Gems erlaubt es hierbei den bestehenden Code mit alter Datenbank, sowie den neuen Microservice mit neuer Datenbank parallel zu betreiben. Anhand der abstrahierten Schnittstelle des QueryExecuters, wird entschieden ob ein Query auf der alten Datenbank oder dem neuen Service stattfindet. Das entsprechende Klassendiagramm ist in \autoref{fig:class} dargestellt.
\begin{figure}[!ht]
    \centering
    \caption{Klassendiagramm zur Verteilung zwischen bestehendem und neu geschaffenem Code}
    \label{fig:class}
    \includegraphics[scale=0.6]{klassendiagramm}
\end{figure}

Ist der Flipper aktiviert, wird zunächst per POST ein Query an den Service übertragen. Im Hintergrund initiiert der Service dann Parsen, Übersetzen und Abarbeiten der Query, dies geschieht asynchron. Zunächst wird die Query in Redis gespeichert und der generierte Zugriffsschlüssel zurückgegeben.
Anhand dieses Schlüssels kann die Hauptanwendung dann die freigegebenen Ergebnisse des Querys, wie die Ids der zutreffenden User, abfragen. Der Ablauf kann wie in \autoref{fig:sequenz} visualisiert werden.

\begin{figure}[!ht]
    \centering
    \caption{Sequenzdiagramm zum Profilqueryen bei aktiviertem Flipper}
    \label{fig:sequenz}
    \includegraphics[width=\textwidth]{prophet_sequenz}
\end{figure}

Hier ist insbesondere das Fehlerhandling zu beachten. Es gibt hier diverse Fehlerquellen die den Ablauf beeinträchtigen können. Zum Einen kann die Query fehlerhaft sein. 
Tritt bei der JSON-Schema Validierung ein Fehler auf, wird hier ein HTTP 422 Statuscode zurückgegeben. Per Definition der Internet Engineering Task Force (IETF)\cite{ietf:424} handelt es sich hierbei um eine ``Unprocessable Entity''. Die übertragenen Daten können also nicht verarbeitet werden.
Da das Parsen der Query asynchron geschieht und die Query vorher nur Anhand von JSON-Schema validiert wird, kann eine fehlerhafte Query, beispielsweise durch illegale Datenbankfeldnamen, erst nach Antwort mit Zugrifssschlüssel erkannt werden. Geschieht dies, muss beim Abfragen der Daten von der API ein eindeutiger Fehlercode zurückgegeben werden. Es muss unterschieden werden können zwischen invaliden Schlüsseln, Timeouts und illegalen Queries. Für Abfragen nach Übermittlung illegaler Queries habe ich den Fehlercode 424 gewählt. Per Definition der IETF\cite{ietf:424}, handelt es sich hierbei um eine `failed dependency'. Der Request ist also fehlgeschlagen, da ein vorheriger Request fehlgeschlagen ist. Dies ist meiner Meinung nach der am besten passende Fehlercode.
Weiterhin kann es natürlich vorkommen, dass die Daten abgefragt werden, obwohl die Query noch nicht abgeschlossen ist. Die Daten liegen schlichtweg nicht vor. Hier wird ein HTTP 428 Statuscode genutzt. Per IETF\cite{ietf:428} steht dieser Statuscode für ``Precondition Required''. Eine benötigte Kondition wurde demnach nicht erfüllt. Dieser Statuscode passt zwar nicht so eindeutig wie der 424 Statuscode, ist aber dennoch eine angemessene Antwort.
Für den Fall, dass der Zugriffsschlüssel selbst nicht valide ist, wird ein simpler 404 Fehlercode zurück gegeben.

Für den den Fehlercode 428 (Query noch nicht abgeschlossen) und sämtliche Netzwerkfehler aus dem Fehlerbereich 500 bis 511, muss sichergestellt werden, dass erneute Abfrageversuche stattfinden.
Ein populärer Ansatz für solche Situationen, ist der des ``Exponential Backoff''\cite{expbackoff}. Bereits im Ethernet Protokoll wird Exponential Backoff eingesetzt\cite{etherbackoff}. Beim Prinzip des Exponential Backoff wird die Zeit zwischen erneuten Versuchen multiplikativ immer weiter erhöht. Die Basisgröße der zeitlichen Abstände kann hier frei gewählt werden. Der zweite Versuch findet hier in der Regel fast direkt nach Fehlschlagen des ersten statt, anschließend werden die Abstände immer größer. Hier wird die Last auf den beteiligten Systemen relativ gering gehalten, eine Operation aber nicht abschließend fehlschlagen gelassen. Grundsätzlich bietet es sich jedoch an, eine Grenze für die Zahl der Fehlerversuche festzulegen (Truncated Exponential Backoff). Wenn der Abstand z.B. auf einen Tag steigt, ist ein erneuter Versuch sicherlich nur noch bedingt sinnvoll.
%(FIX MENTION THAT THIS IS NOT IMPLEMENTED??)

\section{Betrieb der Anwendung auf AWS - Betreuung, Monitoring und Scaling}
Wie bereits beschrieben, bilden die Skalierungsmöglichkeiten von Microservices einen großen Vorteil des Architekturstils. Um diesen optimal ausnutzen zu können, bietet es sich an ein dynamisches Hosting einzurichten. Hier gibt diverse Lösungen, die alle einen ähnlichen Funktionsumfang bieten. Zu nennen sind hier insbesondere Amazon Web Services (AWS), Google App Engine\cite{googleapp} und Heroku\cite{heroku}. Da AWS eine der reifsten Platformen ist und ich mit ihr bereits Erfahrunden sammeln konnte, beschloss ich für den Microservice AWS als Hoster zu wählen.
Auf AWS nutze ich Amazon Beanstalk zum Betreiben der Anwendung. Beanstalk nutzt intern EC2 Instanzen, baut aber eine eigene Konfigurationsschicht darauf auf. Daher muss keine gesamte virtuelle Maschine betrieben werden, stattdessen kann die Anwendung leicht über ein Konfigurationsinterface, wie in \autoref{fig:awsui} dargestellt, gesteuert werden.

\begin{figure}[!ht]
    \centering
    \caption{AWS Beanstalk Konfigurationsinterface}
    \label{fig:awsui}
    \includegraphics[width=\textwidth]{aws_config_ui}
\end{figure}
AWS Beanstalk ist selbst mit keinen Kosten verbunden, die Kosten ergeben sich ausschließlich aus den von Beanstalk genutzten Resourcen, also die genutzten EC2 Instanzen und der reine Speicherverbrauch der Anwendung auf AWS S3. Die weiteren von der Anwendung benötigten Resourcen sind zum Einen eine PostgreSQL Datenbank und der Key-Value Store Redis. Hierfür bietet Amazon jeweils gesonderte Services zum Betrieb. Relationale Datenbanken können über den Amazon Relational Database Service (RDS) genutzt werden, Redis wird über Amazon ElastiCache angeboten. Beide Services bieten ebenso wie Beanstalk gute Skalierungsmöglichkeiten.

Bisher wurden die gesamte Firmenanwendung auf einem System, bei einem Hoster betrieben. Zwar gibt es durchaus separate Repositories um eine API für die mobilen Anwendungen zu bieten, diese werden jedoch immer über das Ruby Webserver Interface in die bestehende Anwendung eingebunden. So werden sie bei jedem Deploy der Hauptanwendung ebenfalls deployt. Weiterhin laufen sie im selben Prozess auf dem gleichen Server wie die Hauptanwendung. Hier ist also keinerlei separates Handling zum Monitoring notwendig. Es kann auch keinen Ausfall eines Teilsystems geben, da alle Teile zusammenhängen. Lediglich die Datenbanken und Redis laufen auf dedizierten Servern, diese werden aber im gleichen Netzwerk betrieben, somit sind zwar Teilausfälle möglich, diese werden durch ein Primary-Secondary System abgesichert, Netzwerkprobleme sind aber in der Regel ausgeschlossen. Das gesamte System kann wie in \autoref{fig:deployd} dargestellt werden.

\begin{figure}[!ht]
    \centering
    \caption{Deploymentdiagramm: Zusammenspiel aller Komponenten}
    \label{fig:deployd}
    \includegraphics[width=\textwidth]{deploymentdiagram}
\end{figure}

Besonders wichtig für den Microservice ist daher das Monitoring der Anwendung und des Servers. Da hier ein von der Hauptanwendung komplett separates System betrieben wird, muss hier sichergestellt werden, dass zum Einen Fehler schnell erkannt und zum Anderen schnell behoben werden. 

Zum Monitoring nutze ich zum Einen Amazons eigene Monitoring Lösung, die über den Gesundheitsstatus der Anwendung informiert. Wechselt die Anwendung vom Gesundheitsstatus ``OK'' in einen anderen, werden die Entwickler direkt über eine Email informiert.

Zusätzlich zum allgemeinen Ausfallmonitoring durch Amazon, integrierte ich das Monitoring Tool Skylight\cite{skylight} in die Anwendung. Im bisherigen Betriebssetup wird aktuell NewRelic\cite{newrelic} zum Monitoring eingesetzt. Skylight zeichnet sich jedoch durch einen besonders geringen Overhead aus, was sich beim Microservice durchaus anbietet. Skylight informiert ebenfalls per Email über Ausfälle und zeichnet allgemein die Performance des Systems auf. So kann zu jedem Zeitpunkt der Vergangenheit, über Wochen hinweg, detailliert die Performance des Sytsems nachvollzogen werden. Zusätzlich zu allgemeinen Aufzeichnungen der Response time, kann hier nach Datenbankabfragen unterschieden werden. So wird schnell deutlich, welche Anfragen besonders zeitintensiv sind und wo Handlungsbedarf oder Verbesserungsmöglichkeiten bestehen. 

Als Fehlerreporting Tool kommt im Microservice Bugsnag\cite{bugsnag} zum Einsatz. Bugsnag wird bereits als primäres Firmentool verwendet und eignet sich ebenfalls gut für kleine Anwendungen. Bugsnag zeichnet Fehler im System mit Stacktrace auf und informiert die Entwickler ebenfalls per Email.

Das informieren über Fehler per Email ist im Betrieb ein durchaus üblicher Weg, daher eignet sich diese Integration auch für den neuen Service. Weiterhin besteht in der Firma ein Dashboard, was zwar nicht die Performance des neuen Microservices an sich, aber die Gesamtperformance des Sampling Prozesses darstellt. Dieser umschließt alles vom Erstellen der Query, der Abfrage des neuen Services, bis hin zum verarbeiten und anzeigen der Queryergebnisse. So können Probleme auf dem Dashboard leicht von den Entwicklern bemerkt werden. All dies sind im Live Betrieb erprobte Techniken und eignen sich dadurch sehr gut für die Ausweitung auf neue Services.